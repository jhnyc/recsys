{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide and Deep Learning (https://arxiv.org/pdf/1606.07792.pdf)\n",
    "\n",
    "- a \"wide\" component that uses embedding layers to represent users and items\n",
    "  - wide linear layer to learn interaction & co-occurence between features\n",
    "- a \"deep\" component that uses fully-connected layers to learn the interactions between users and items\n",
    "  - embedding based MLP to generalize to unseen item feature pairs\n",
    "  - deep learning to model complex feature interactions\n",
    "- The final output is the sum of the outputs from the wide and deep components.\n",
    "- The idea of Wide and Deep Learning is to achieve both **memorization** and **generalization**\n",
    "- Focus on ranking of items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model_illustration.png\" style=\"width:700px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideDeep(nn.Module):\n",
    "    def __init__(self, n_fields, n_features, mlp_dims=[256, 128, 64], embed_dim=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # wide linear component\n",
    "        self.linear = nn.Embedding(n_features, 1)\n",
    "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
    "        # deep mlp component\n",
    "        self.embedding = nn.Embedding(n_features, embed_dim)\n",
    "        self.embed_out_dim = n_fields*embed_dim\n",
    "        mlp_layers = []\n",
    "        input_dim = self.embed_out_dim \n",
    "        for dim in mlp_dims:\n",
    "            mlp_layers.append(nn.Linear(input_dim, dim))\n",
    "            mlp_layers.append(nn.BatchNorm1d(dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(dropout))\n",
    "            input_dim = dim\n",
    "        mlp_layers.append(nn.Linear(input_dim, 1)) # final output layer\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x).view(-1, self.embed_out_dim)\n",
    "        x = self.bias + self.linear(x).sum(dim=1) + self.mlp(x_embed)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,  dataloader, epochs=20, lr=0.001):\n",
    "    device = (\n",
    "        torch.device(\"cuda:0\") if torch.cuda.is_available(\n",
    "        ) else torch.device(\"cpu\")\n",
    "    )\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    training_history = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            y_pred = model.forward(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            epoch_loss += loss\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss /= len(dataloader)\n",
    "        training_history.append(epoch_loss)\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"Epoch {epoch}: {epoch_loss:.4f}\")\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "- X is an array of feature indices (n_samples, n_attributes), where each feature index will be mapped to a latent factor\n",
    "  - [user, item, user_features, item_features]\n",
    "- y is just a (n_sample, 1) array of the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie, rating = utils.load_movielens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode movie features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an array of feature indices for each item\n",
    "all_movie_features = set([f for feat in movie['features'] for f in feat])\n",
    "feature_to_id = {f:ix for ix, f in enumerate(all_movie_features)}\n",
    "movie_feat_id = movie['features'].apply(lambda x: [feature_to_id[f]+1 for f in x]).to_list() # +1 since 0 is the null feature\n",
    "\n",
    "# since items have variable # of features, pad feature sequence with 0 \n",
    "features_enc = pad_sequence([torch.tensor(i) for i in movie_feat_id], batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine userId, movieId and features to get our `x`\n",
    "- [userId, movieId, feature-1, feature-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = rating['userId'].nunique()\n",
    "n_movies = movie['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   30,   22, ...,    0,    0,    0],\n",
       "       [   0,  833,   19, ...,    0,    0,    0],\n",
       "       [   0,  859,   16, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 670, 4603,   13, ...,    0,    0,    0],\n",
       "       [ 670, 4616,   22, ...,    0,    0,    0],\n",
       "       [ 670, 4703,   22, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join userid & movieid, and features\n",
    "x = rating[['userId', 'movieId']].to_numpy()\n",
    "features = features_enc[rating['movieId']]\n",
    "x = np.hstack((x, features))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  701, 9818, ..., 9796, 9796, 9796],\n",
       "       [   0, 1504, 9815, ..., 9796, 9796, 9796],\n",
       "       [   0, 1530, 9812, ..., 9796, 9796, 9796],\n",
       "       ...,\n",
       "       [ 670, 5274, 9809, ..., 9796, 9796, 9796],\n",
       "       [ 670, 5287, 9818, ..., 9796, 9796, 9796],\n",
       "       [ 670, 5374, 9818, ..., 9796, 9796, 9796]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate offset, avoid duplicated feature indices\n",
    "x[:, 1] += n_user\n",
    "x[:, 2:] += n_user+n_movies\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "y = np.where(rating['rating'].to_numpy() > threshold, 1, 0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train & test set\n",
    "- train: first n-1 ratings per user (n is the number of ratings of the user)\n",
    "- test: last/most recent rating per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ix = [i for i,v in enumerate(x[:-1, 0]) if v != x[i+1,0]] + [len(x)-1]\n",
    "train_ix = [i for i in range(len(x)) if i not in test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x[train_ix], x[test_ix]\n",
    "y_train, y_test = y[train_ix], y[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train).float())\n",
    "train_dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = n_user + n_movies + len(all_movie_features) + 1 # +1 for the null feature\n",
    "n_fields = x_train.shape[1]\n",
    "embed_dim = 20\n",
    "\n",
    "model = WideDeep(n_fields=n_fields, \n",
    "                 n_features=n_features, \n",
    "                 mlp_dims=[128, 64], \n",
    "                 embed_dim=embed_dim, \n",
    "                 dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7988\n",
      "Epoch 10: 0.4995\n",
      "Epoch 20: 0.4489\n",
      "Epoch 30: 0.4072\n",
      "Epoch 40: 0.3728\n",
      "Epoch 50: 0.3430\n",
      "Epoch 60: 0.3206\n",
      "Epoch 70: 0.2984\n",
      "Epoch 80: 0.2863\n",
      "Epoch 90: 0.2683\n",
      "Epoch 100: 0.2588\n",
      "Epoch 110: 0.2529\n",
      "Epoch 120: 0.2402\n",
      "Epoch 130: 0.2306\n",
      "Epoch 140: 0.2250\n",
      "Epoch 150: 0.2203\n",
      "Epoch 160: 0.2132\n",
      "Epoch 170: 0.2101\n",
      "Epoch 180: 0.2056\n",
      "Epoch 190: 0.2015\n"
     ]
    }
   ],
   "source": [
    "model, history = train(model, train_dataloader, epochs=200, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(torch.from_numpy(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6751117734724292"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.where(y_pred.numpy()>0.5, 1,0), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6898539508671667"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d59829e856ecc8da3b928adad583801194efdadc7aa71fa7c39d3d39c851f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
