{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Tower (https://storage.googleapis.com/pub-tools-public-publication-data/pdf/6c8a86c981a62b0126a11896b7f6ae0dae4c3566.pdf)\n",
    "- as the name suggests, the model consists of two MLP layers\n",
    "- user & item encoder: neural nets that take features about the item and users and encode them into fixed dimension embedding vectors\n",
    "- user and item embedding vectors are finally multiplied to get the prediction\n",
    "- this architecture is widely used for retrieval because of it's scalibility\n",
    "  - since user & item features don't interact early on, we don't need to pass the user & item features through the complex neural network to get our prediction\n",
    "  - user & item feature embeddings can be precomputed, and at serve time, we just multiply the user's embedding vector with all the item embeddings\n",
    "  - instead of naively multiplying the user embedding with all item embeddings, which has a linear time complexity, a more efficient approach would be to do a approximate nearest neighbor (ANN) to narrow down the number of items by searching for the top k most similar items based on the user embedding (since similar vectors will have a larger dot product), before passing to a ranking model\n",
    "  \n",
    "The model architecture is nicely illustrated here ([image source](https://www.linkedin.com/pulse/personalized-recommendations-iv-two-tower-models-gaurav-chakravorty/)):\n",
    "\n",
    "<img src=\"model_illustration.png\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTower(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_item_features,\n",
    "        n_user_features,\n",
    "        n_item_fields,\n",
    "        n_user_fields,\n",
    "        embed_dim,\n",
    "        mlp_out_embed_dim,\n",
    "        item_mlp_dims,\n",
    "        user_mlp_dims=None,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_item_fields = n_item_fields\n",
    "        self.n_user_fields = n_user_fields\n",
    "        \n",
    "        # item tower\n",
    "        self.item_embedding = nn.Embedding(n_item_features, embed_dim)\n",
    "        self.item_mlp_input_dim = n_item_fields * embed_dim\n",
    "        item_mlp_input_dim = self.item_mlp_input_dim\n",
    "        item_mlp_layers = []\n",
    "        for dim in item_mlp_dims:\n",
    "            item_mlp_layers.append(nn.Linear(item_mlp_input_dim, dim))\n",
    "            item_mlp_layers.append(nn.BatchNorm1d(dim))\n",
    "            item_mlp_layers.append(nn.ReLU())\n",
    "            item_mlp_layers.append(nn.Dropout(dropout))\n",
    "            item_mlp_input_dim = dim\n",
    "        item_mlp_layers.append(nn.Linear(item_mlp_input_dim, mlp_out_embed_dim))\n",
    "        self.item_mlp = nn.Sequential(*item_mlp_layers)\n",
    "\n",
    "        # user tower\n",
    "        self.user_embedding = nn.Embedding(n_user_features, embed_dim)\n",
    "        self.user_mlp_input_dim = n_user_fields * embed_dim\n",
    "        user_mlp_input_dim = self.user_mlp_input_dim\n",
    "        user_mlp_layers = []\n",
    "        user_mlp_dims = (\n",
    "            user_mlp_dims if user_mlp_dims else item_mlp_dims\n",
    "        )  # if user_mlp_dims not specified, use the same mlp structure as item\n",
    "        for dim in user_mlp_dims:\n",
    "            user_mlp_layers.append(nn.Linear(user_mlp_input_dim, dim))\n",
    "            user_mlp_layers.append(nn.BatchNorm1d(dim))\n",
    "            user_mlp_layers.append(nn.ReLU())\n",
    "            user_mlp_layers.append(nn.Dropout(dropout))\n",
    "            user_mlp_input_dim = dim\n",
    "        user_mlp_layers.append(nn.Linear(user_mlp_input_dim, mlp_out_embed_dim))\n",
    "        self.user_mlp = nn.Sequential(*user_mlp_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape : [[item_feature_1...item_feature_n, user_feature_1...user_feature_n]]\n",
    "        # concat each item's embeddings to a 1d vector\n",
    "        item_embed = self.item_embedding(x[:, :self.n_item_fields]).view(-1, self.item_mlp_input_dim)\n",
    "        # concat each user's embeddings to a 1d vector\n",
    "        user_embed = self.user_embedding(x[:, self.n_item_fields:]).view(-1, self.user_mlp_input_dim)\n",
    "        # pass feature embeddings through mlp to output user & item embeddings\n",
    "        item_mlp_embed = self.item_mlp(item_embed)\n",
    "        user_mlp_embed = self.user_mlp(user_embed)\n",
    "        # dot product of item & user embeddings\n",
    "        dot = (item_mlp_embed * user_mlp_embed).sum(dim=1)\n",
    "        return torch.sigmoid(dot)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epochs=20, lr=0.001):\n",
    "    device = (\n",
    "        torch.device(\"cuda:0\") if torch.cuda.is_available(\n",
    "        ) else torch.device(\"cpu\")\n",
    "    )\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    training_history = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            y_pred = model.forward(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            epoch_loss += loss\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss /= len(dataloader)\n",
    "        training_history.append(epoch_loss)\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"Epoch {epoch}: {epoch_loss:.4f}\")\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "- X is an array of feature indices: [[item_feature_1...item_feature_n, user_feature_1...user_feature_n]]\n",
    "- y is just a (n_sample, 1) array of the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating, item, user = utils.get_movielens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_label = utils.get_items_label_encoding(item, return_df=False)\n",
    "user_label = utils.get_users_label_encoding(user, return_df=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat item & user feature matrix to get X\n",
    "X = np.hstack((item_label[rating['item_id']-1,:], user_label[rating['user_id']-1,:])) # offset -1 since item&user id starts with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rating to 1/0\n",
    "threshold = 3\n",
    "y = np.where(rating['rating'].to_numpy()>=threshold, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split\n",
    "\n",
    "Here, for simplicity, we are only using a random split, with 80% as the train set, and 20% as the test set. In practice, the splitting maybe done by user, e.g. 80/20 split of a user's rating/interaction history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train).float())\n",
    "train_dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_features = np.max(item_label)+1\n",
    "n_user_features = np.max(user_label)+1\n",
    "n_item_fields = item_label.shape[-1]\n",
    "n_user_fields = user_label.shape[-1]\n",
    "embed_dim = 50\n",
    "mlp_out_embed_dim = 64\n",
    "item_mlp_dims = [128, 64]\n",
    "\n",
    "model = TwoTower(\n",
    "    n_item_features=n_item_features,\n",
    "    n_user_features=n_user_features,\n",
    "    n_item_fields=n_item_fields,\n",
    "    n_user_fields=n_user_fields,\n",
    "    embed_dim=embed_dim,\n",
    "    mlp_out_embed_dim=mlp_out_embed_dim,\n",
    "    item_mlp_dims=item_mlp_dims,\n",
    "    user_mlp_dims=None,\n",
    "    dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.4428\n",
      "Epoch 10: 0.3273\n",
      "Epoch 20: 0.2862\n",
      "Epoch 30: 0.2574\n",
      "Epoch 40: 0.2353\n",
      "Epoch 50: 0.2210\n",
      "Epoch 60: 0.2081\n",
      "Epoch 70: 0.1973\n",
      "Epoch 80: 0.1894\n",
      "Epoch 90: 0.1820\n"
     ]
    }
   ],
   "source": [
    "model, history = train(model=model, \n",
    "                       dataloader=train_dataloader, \n",
    "                       epochs=100, \n",
    "                       lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_soft = model.predict(torch.from_numpy(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred_soft.numpy() > 0.5, 1, 0)\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "auc = roc_auc_score(y_test, y_pred_soft)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cf_mat = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8256\n",
      "AUC: 0.778323289898644\n",
      "F1 Score: 0.8967314069161535\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1368,  2100],\n",
       "       [ 1388, 15144]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top K(10) precision: 0.013829787234042556\n",
      "Top K(10) recall: 0.008143358090614682\n"
     ]
    }
   ],
   "source": [
    "top = 10\n",
    "top_k_precision, top_k_recall = utils.top_k_precision_recall(\n",
    "    model, X_train, X_test, y_test, item_label, top=top, user_id_col=item_label.shape[1])\n",
    "\n",
    "print(f\"Top K({top}) precision: {top_k_precision}\")\n",
    "print(f\"Top K({top}) recall: {top_k_recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d59829e856ecc8da3b928adad583801194efdadc7aa71fa7c39d3d39c851f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
